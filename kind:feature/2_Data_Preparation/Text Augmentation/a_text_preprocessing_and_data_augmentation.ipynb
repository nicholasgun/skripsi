{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../../../Data/Preprocessed Data/kind:feature/merged_data_with_comments.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments_url</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>pr_url</th>\n",
       "      <th>labels</th>\n",
       "      <th>pr_number</th>\n",
       "      <th>filename</th>\n",
       "      <th>status</th>\n",
       "      <th>additions</th>\n",
       "      <th>deletions</th>\n",
       "      <th>changes</th>\n",
       "      <th>all_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/kubernetes/kubern...</td>\n",
       "      <td>275859420</td>\n",
       "      <td>Kubelet flag precedence order vs files/ConfigM...</td>\n",
       "      <td>See https://docs.google.com/document/d/18-MsCh...</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/issue...</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/pull/...</td>\n",
       "      <td>[area/kubelet, area/kubelet-api]</td>\n",
       "      <td>56097</td>\n",
       "      <td>['cmd/kubelet/kubelet.go', 'hack/make-rules/te...</td>\n",
       "      <td>['modified', 'modified', 'modified', 'modified...</td>\n",
       "      <td>[7, 1, 21, 1, 1, 1, 1, 1, 1, 15, 139, 146]</td>\n",
       "      <td>[1, 0, 4, 0, 0, 1, 1, 1, 1, 0, 9, 0]</td>\n",
       "      <td>[8, 1, 25, 1, 1, 2, 2, 2, 2, 15, 148, 146]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/kubernetes/kubead...</td>\n",
       "      <td>262492428</td>\n",
       "      <td>Individual control of preflight checks</td>\n",
       "      <td>Many times users know better than kubeadm arou...</td>\n",
       "      <td>https://github.com/kubernetes/kubeadm/issues/480</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/pull/...</td>\n",
       "      <td>[area/kubeadm]</td>\n",
       "      <td>56072</td>\n",
       "      <td>['cmd/kubeadm/app/apis/kubeadm/validation/BUIL...</td>\n",
       "      <td>['modified', 'modified', 'modified', 'modified...</td>\n",
       "      <td>[1, 26, 29, 20, 21, 1, 3, 17, 4, 2, 6, 3, 5, 6...</td>\n",
       "      <td>[0, 1, 0, 14, 15, 0, 2, 9, 0, 0, 1, 7, 1, 0, 0...</td>\n",
       "      <td>[1, 27, 29, 34, 36, 1, 5, 26, 4, 2, 7, 10, 6, ...</td>\n",
       "      <td>New example in 1.8.0:\\r\\nsystemctl start kubel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/kubernetes/kubern...</td>\n",
       "      <td>275470204</td>\n",
       "      <td>seccomp is an alpha feature and not feature gated</td>\n",
       "      <td>see #55983</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/issue...</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/pull/...</td>\n",
       "      <td>[area/kubelet, area/kubelet-api]</td>\n",
       "      <td>55983</td>\n",
       "      <td>['cmd/kubelet/app/options/options.go', 'cmd/ku...</td>\n",
       "      <td>['modified', 'modified', 'modified', 'modified...</td>\n",
       "      <td>[5, 6, 0, 0, 0, 0, 0, 0, 5]</td>\n",
       "      <td>[1, 3, 1, 1, 2, 4, 2, 2, 3]</td>\n",
       "      <td>[6, 9, 1, 1, 2, 4, 2, 2, 8]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/kubernetes/kubead...</td>\n",
       "      <td>272308417</td>\n",
       "      <td>Use ComponentConfig for the kube-proxy</td>\n",
       "      <td>Important feature for v1.9; dependency for IPv...</td>\n",
       "      <td>https://github.com/kubernetes/kubeadm/issues/527</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/pull/...</td>\n",
       "      <td>[area/ipv6]</td>\n",
       "      <td>55972</td>\n",
       "      <td>['cmd/kubeadm/app/apis/kubeadm/BUILD', 'cmd/ku...</td>\n",
       "      <td>['modified', 'modified', 'modified', 'modified...</td>\n",
       "      <td>[1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, ...</td>\n",
       "      <td>[1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/kubernetes/kubern...</td>\n",
       "      <td>251361039</td>\n",
       "      <td>Add kubeadm config for setting kube-proxy Bind...</td>\n",
       "      <td>&lt;!-- This form is for bug reports and feature ...</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/issue...</td>\n",
       "      <td>https://github.com/kubernetes/kubernetes/pull/...</td>\n",
       "      <td>[area/ipv6]</td>\n",
       "      <td>55972</td>\n",
       "      <td>['cmd/kubeadm/app/apis/kubeadm/BUILD', 'cmd/ku...</td>\n",
       "      <td>['modified', 'modified', 'modified', 'modified...</td>\n",
       "      <td>[1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, ...</td>\n",
       "      <td>[1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...</td>\n",
       "      <td>/sig cluster-lifecycle\\r\\n/area ipv6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comments_url         id  \\\n",
       "0  https://api.github.com/repos/kubernetes/kubern...  275859420   \n",
       "1  https://api.github.com/repos/kubernetes/kubead...  262492428   \n",
       "2  https://api.github.com/repos/kubernetes/kubern...  275470204   \n",
       "3  https://api.github.com/repos/kubernetes/kubead...  272308417   \n",
       "4  https://api.github.com/repos/kubernetes/kubern...  251361039   \n",
       "\n",
       "                                               title  \\\n",
       "0  Kubelet flag precedence order vs files/ConfigM...   \n",
       "1             Individual control of preflight checks   \n",
       "2  seccomp is an alpha feature and not feature gated   \n",
       "3             Use ComponentConfig for the kube-proxy   \n",
       "4  Add kubeadm config for setting kube-proxy Bind...   \n",
       "\n",
       "                                                body  \\\n",
       "0  See https://docs.google.com/document/d/18-MsCh...   \n",
       "1  Many times users know better than kubeadm arou...   \n",
       "2                                         see #55983   \n",
       "3  Important feature for v1.9; dependency for IPv...   \n",
       "4  <!-- This form is for bug reports and feature ...   \n",
       "\n",
       "                                           issue_url  \\\n",
       "0  https://github.com/kubernetes/kubernetes/issue...   \n",
       "1   https://github.com/kubernetes/kubeadm/issues/480   \n",
       "2  https://github.com/kubernetes/kubernetes/issue...   \n",
       "3   https://github.com/kubernetes/kubeadm/issues/527   \n",
       "4  https://github.com/kubernetes/kubernetes/issue...   \n",
       "\n",
       "                                              pr_url  \\\n",
       "0  https://github.com/kubernetes/kubernetes/pull/...   \n",
       "1  https://github.com/kubernetes/kubernetes/pull/...   \n",
       "2  https://github.com/kubernetes/kubernetes/pull/...   \n",
       "3  https://github.com/kubernetes/kubernetes/pull/...   \n",
       "4  https://github.com/kubernetes/kubernetes/pull/...   \n",
       "\n",
       "                             labels  pr_number  \\\n",
       "0  [area/kubelet, area/kubelet-api]      56097   \n",
       "1                    [area/kubeadm]      56072   \n",
       "2  [area/kubelet, area/kubelet-api]      55983   \n",
       "3                       [area/ipv6]      55972   \n",
       "4                       [area/ipv6]      55972   \n",
       "\n",
       "                                            filename  \\\n",
       "0  ['cmd/kubelet/kubelet.go', 'hack/make-rules/te...   \n",
       "1  ['cmd/kubeadm/app/apis/kubeadm/validation/BUIL...   \n",
       "2  ['cmd/kubelet/app/options/options.go', 'cmd/ku...   \n",
       "3  ['cmd/kubeadm/app/apis/kubeadm/BUILD', 'cmd/ku...   \n",
       "4  ['cmd/kubeadm/app/apis/kubeadm/BUILD', 'cmd/ku...   \n",
       "\n",
       "                                              status  \\\n",
       "0  ['modified', 'modified', 'modified', 'modified...   \n",
       "1  ['modified', 'modified', 'modified', 'modified...   \n",
       "2  ['modified', 'modified', 'modified', 'modified...   \n",
       "3  ['modified', 'modified', 'modified', 'modified...   \n",
       "4  ['modified', 'modified', 'modified', 'modified...   \n",
       "\n",
       "                                           additions  \\\n",
       "0         [7, 1, 21, 1, 1, 1, 1, 1, 1, 15, 139, 146]   \n",
       "1  [1, 26, 29, 20, 21, 1, 3, 17, 4, 2, 6, 3, 5, 6...   \n",
       "2                        [5, 6, 0, 0, 0, 0, 0, 0, 5]   \n",
       "3  [1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...   \n",
       "4  [1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...   \n",
       "\n",
       "                                           deletions  \\\n",
       "0               [1, 0, 4, 0, 0, 1, 1, 1, 1, 0, 9, 0]   \n",
       "1  [0, 1, 0, 14, 15, 0, 2, 9, 0, 0, 1, 7, 1, 0, 0...   \n",
       "2                        [1, 3, 1, 1, 2, 4, 2, 2, 3]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, ...   \n",
       "\n",
       "                                             changes  \\\n",
       "0         [8, 1, 25, 1, 1, 2, 2, 2, 2, 15, 148, 146]   \n",
       "1  [1, 27, 29, 34, 36, 1, 5, 26, 4, 2, 7, 10, 6, ...   \n",
       "2                        [6, 9, 1, 1, 2, 4, 2, 2, 8]   \n",
       "3  [1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...   \n",
       "4  [1, 1, 36, 7, 3, 25, 7, 29, 27, 4, 6, 18, 15, ...   \n",
       "\n",
       "                                        all_comments  \n",
       "0                                                     \n",
       "1  New example in 1.8.0:\\r\\nsystemctl start kubel...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4               /sig cluster-lifecycle\\r\\n/area ipv6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Title, Description, and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new column with title, and body all together\n",
    "data['all_text'] = data['title'] + ' ' + data['body'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase everything\n",
    "data['all_text'] = data['all_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line break removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove line breaks (\\r, \\n)\n",
    "data['all_text'] = data['all_text'].str.replace('\\r', ' ')\n",
    "data['all_text'] = data['all_text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Non-alphanumeric character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-alphanumeric characters such as punctuation, symbols, emojis, etc.\n",
    "data['all_text'] = data['all_text'].str.replace(r'[^a-zA-Z0-9 ]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the datatype to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype to string\n",
    "data['all_text'] = data['all_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    kubelet flag precedence order vs files/configm...\n",
      "1    individual control of preflight checks many ti...\n",
      "2    seccomp is an alpha feature and not feature ga...\n",
      "3    use componentconfig for the kube-proxy importa...\n",
      "4    add kubeadm config for setting kube-proxy bind...\n",
      "Name: all_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the first 5 rows of the all_text and all_comments\n",
    "print(data['all_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with threshold: 0.5\n",
      "  Vocabulary size: 10084\n",
      "  Average words per document: 84.37\n"
     ]
    }
   ],
   "source": [
    "# Remove high frequency words with threshold 0.5\n",
    "threshold = 0.5\n",
    "print(f\"Processing with threshold: {threshold}\")\n",
    "\n",
    "# Create and fit CountVectorizer\n",
    "cv = CountVectorizer(max_df=threshold)\n",
    "cv.fit(data['all_text'])\n",
    "\n",
    "# Get vocabulary from fitted vectorizer\n",
    "vocabulary = cv.vocabulary_\n",
    "\n",
    "# Filter each document to only keep words in the vocabulary\n",
    "filtered_texts = []\n",
    "for text in data['all_text']:\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word in vocabulary]\n",
    "    filtered_texts.append(' '.join(filtered_words))\n",
    "\n",
    "# Store filtered texts in same column\n",
    "data['all_text'] = filtered_texts\n",
    "\n",
    "# Print statistics\n",
    "print(f\"  Vocabulary size: {len(vocabulary)}\")\n",
    "print(f\"  Average words per document: {sum(len(text.split()) for text in filtered_texts) / len(filtered_texts):.2f}\")# Export vocabulary to file\n",
    "\n",
    "vocab_df = pd.DataFrame(list(vocabulary.items()), columns=['Word', 'Index'])\n",
    "vocab_df = vocab_df.sort_values('Index')\n",
    "vocab_df.to_csv('vocabulary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the label by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Length Distribution:\n",
      "Mean: 1.76\n",
      "Min: 1\n",
      "Max: 16\n",
      "\n",
      "Number of issues by label count:\n",
      "1 label(s): 508 issues (58.39%)\n",
      "2 label(s): 233 issues (26.78%)\n",
      "3 label(s): 61 issues (7.01%)\n",
      "4 label(s): 33 issues (3.79%)\n",
      "5 label(s): 12 issues (1.38%)\n",
      "6 label(s): 9 issues (1.03%)\n",
      "7 label(s): 8 issues (0.92%)\n",
      "8 label(s): 1 issues (0.11%)\n",
      "10 label(s): 1 issues (0.11%)\n",
      "11 label(s): 1 issues (0.11%)\n",
      "13 label(s): 1 issues (0.11%)\n",
      "14 label(s): 1 issues (0.11%)\n",
      "16 label(s): 1 issues (0.11%)\n"
     ]
    }
   ],
   "source": [
    "# Check the length (number of labels) for each issue\n",
    "label_lengths = data['labels'].apply(len)\n",
    "\n",
    "# Print label length statistics\n",
    "print(\"Label Length Distribution:\")\n",
    "print(f\"Mean: {label_lengths.mean():.2f}\")\n",
    "print(f\"Min: {label_lengths.min()}\")\n",
    "print(f\"Max: {label_lengths.max()}\")\n",
    "\n",
    "# Get counts of each label length\n",
    "length_counts = Counter(label_lengths)\n",
    "\n",
    "# Print distribution\n",
    "print(\"\\nNumber of issues by label count:\")\n",
    "for length, count in sorted(length_counts.items()):\n",
    "    print(f\"{length} label(s): {count} issues ({count/len(data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the label length (max 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after filtering: 847 entries\n",
      "Percentage of original data kept: 97.36%\n"
     ]
    }
   ],
   "source": [
    "# Original size of the dataset\n",
    "original_size = len(data)\n",
    "\n",
    "# Filter data to only include entries with 5 or fewer labels\n",
    "data = data[data['labels'].apply(len) <= 5]\n",
    "\n",
    "# Print information about the filtered dataset\n",
    "print(f\"Dataset size after filtering: {len(data)} entries\")\n",
    "\n",
    "print(f\"Percentage of original data kept: {len(data)/original_size*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Label Length Distribution:\n",
      "Mean: 1.41\n",
      "Min: 1\n",
      "Max: 5\n",
      "\n",
      "Number of issues by label count:\n",
      "1 label(s): 894 issues (72.33%)\n",
      "2 label(s): 251 issues (20.31%)\n",
      "3 label(s): 46 issues (3.72%)\n",
      "4 label(s): 22 issues (1.78%)\n",
      "5 label(s): 23 issues (1.86%)\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the label length statistics\n",
    "filtered_label_lengths = data['labels'].apply(len)\n",
    "filtered_length_counts = Counter(filtered_label_lengths)\n",
    "\n",
    "print(\"\\nFiltered Label Length Distribution:\")\n",
    "print(f\"Mean: {filtered_label_lengths.mean():.2f}\")\n",
    "print(f\"Min: {filtered_label_lengths.min()}\")\n",
    "print(f\"Max: {filtered_label_lengths.max()}\")\n",
    "\n",
    "# Print distribution\n",
    "print(\"\\nNumber of issues by label count:\")\n",
    "for length, count in sorted(filtered_length_counts.items()):\n",
    "    print(f\"{length} label(s): {count} issues ({count/len(data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Count:\n",
      "area/kubelet: 157\n",
      "area/kubelet-api: 5\n",
      "area/kubeadm: 85\n",
      "area/ipv6: 4\n",
      "area/hw-accelerators: 2\n",
      "area/provider/openstack: 3\n",
      "area/client-libraries: 2\n",
      "area/apiserver: 156\n",
      "area/etcd: 1\n",
      "area/kubectl: 132\n",
      "area/code-generation: 61\n",
      "area/test: 433\n",
      "area/conformance: 21\n",
      "area/cloudprovider: 52\n",
      "area/provider/azure: 14\n",
      "area/dependency: 51\n",
      "area/ipvs: 9\n",
      "area/e2e-test-framework: 86\n",
      "area/custom-resources: 5\n",
      "area/admission-control: 5\n",
      "area/security: 1\n",
      "area/test-infra: 1\n",
      "area/release-eng: 22\n",
      "area/provider/gcp: 15\n",
      "area/code-organization: 2\n",
      "area/batch: 1\n",
      "area/workload-api/job: 1\n",
      "area/network-policy: 3\n",
      "area/kube-proxy: 13\n",
      "area/stable-metrics: 4\n",
      "area/logging: 2\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of labels if it's a list of lists\n",
    "flattened_labels = [label for sublist in data['labels'] for label in sublist]\n",
    "\n",
    "# Print labels distribution count\n",
    "label_counts = Counter(flattened_labels)\n",
    "print(\"Label Distribution Count:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove labels that have occurence < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 1349 total label occurrences\n",
      "Removing 13 rare label types with fewer than 5 occurrences:\n",
      "  - area/ipv6: 4 occurrences\n",
      "  - area/hw-accelerators: 2 occurrences\n",
      "  - area/provider/openstack: 3 occurrences\n",
      "  - area/client-libraries: 2 occurrences\n",
      "  - area/etcd: 1 occurrences\n",
      "  - area/security: 1 occurrences\n",
      "  - area/test-infra: 1 occurrences\n",
      "  - area/code-organization: 2 occurrences\n",
      "  - area/batch: 1 occurrences\n",
      "  - area/workload-api/job: 1 occurrences\n",
      "  - area/network-policy: 3 occurrences\n",
      "  - area/stable-metrics: 4 occurrences\n",
      "  - area/logging: 2 occurrences\n",
      "\n",
      "After filtering:\n",
      "  - Original dataset size: 847 issues\n",
      "  - Remaining dataset size: 835 issues\n",
      "  - Removed 12 issues (1.42%)\n",
      "  - Remaining label occurrences: 1322\n"
     ]
    }
   ],
   "source": [
    "# Get original data size for comparison\n",
    "original_size = len(data)\n",
    "\n",
    "# Filter the labels that have less than 5 occurrences\n",
    "rare_labels = [label for label, count in label_counts.items() if count < 5]\n",
    "common_labels = [label for label, count in label_counts.items() if count >= 5]\n",
    "\n",
    "print(f\"Before filtering: {len(flattened_labels)} total label occurrences\")\n",
    "print(f\"Removing {len(rare_labels)} rare label types with fewer than 5 occurrences:\")\n",
    "for label in rare_labels:\n",
    "    print(f\"  - {label}: {label_counts[label]} occurrences\")\n",
    "\n",
    "# Update data to keep only issues that have at least one common label\n",
    "data['labels'] = data['labels'].apply(lambda x: [label for label in x if label in common_labels])\n",
    "data = data[data['labels'].apply(len) > 0]\n",
    "\n",
    "# Print statistics after filtering\n",
    "remaining_size = len(data)\n",
    "removed_count = original_size - remaining_size\n",
    "removed_percentage = (removed_count / original_size) * 100\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"  - Original dataset size: {original_size} issues\")\n",
    "print(f\"  - Remaining dataset size: {remaining_size} issues\")\n",
    "print(f\"  - Removed {removed_count} issues ({removed_percentage:.2f}%)\")\n",
    "\n",
    "# Update flattened_labels to reflect the current state\n",
    "flattened_labels = [label for sublist in data['labels'] for label in sublist]\n",
    "print(f\"  - Remaining label occurrences: {len(flattened_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Count:\n",
      "1. area/test: 433\n",
      "2. area/kubelet: 157\n",
      "3. area/apiserver: 156\n",
      "4. area/kubectl: 132\n",
      "5. area/e2e-test-framework: 86\n",
      "6. area/kubeadm: 85\n",
      "7. area/code-generation: 61\n",
      "8. area/cloudprovider: 52\n",
      "9. area/dependency: 51\n",
      "10. area/release-eng: 22\n",
      "11. area/conformance: 21\n",
      "12. area/provider/gcp: 15\n",
      "13. area/provider/azure: 14\n",
      "14. area/kube-proxy: 13\n",
      "15. area/ipvs: 9\n",
      "16. area/kubelet-api: 5\n",
      "17. area/custom-resources: 5\n",
      "18. area/admission-control: 5\n"
     ]
    }
   ],
   "source": [
    "# Print labels distribution count\n",
    "label_counts = Counter(flattened_labels)\n",
    "print(\"Label Distribution Count:\")\n",
    "\n",
    "for i, (label, count) in enumerate(sorted(label_counts.items(), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"{i+1}. {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels...\n",
      "Training samples: 668, Validation samples: 167\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility (same seed used in DeBERTa script)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prepare for train-test split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Encode multi-labels using MultiLabelBinarizer\n",
    "print(\"Encoding labels...\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(data['labels'])\n",
    "\n",
    "# Split data into training and validation sets (80% training, 20% validation)\n",
    "split_idx = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:split_idx].reset_index(drop=True)\n",
    "val_data = data.iloc[split_idx:].reset_index(drop=True)\n",
    "train_labels = labels_encoded[:split_idx]\n",
    "val_labels = labels_encoded[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}, Validation samples: {len(val_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the train_data and val_data to csv\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "val_data.to_csv('val_data.csv', index=False)\n",
    "\n",
    "# # export the train_labels and val_labels to csv\n",
    "# # Convert numpy arrays to DataFrame before exporting to csv\n",
    "# train_labels_df = pd.DataFrame(train_labels)\n",
    "# val_labels_df = pd.DataFrame(val_labels)\n",
    "# train_labels_df.to_csv('train_labels.csv', index=False)\n",
    "# val_labels_df.to_csv('val_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
